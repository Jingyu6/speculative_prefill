Meta-Llama-3.1-8B-Instruct:
  prompt_template: "Meta-Llama-3.1-8B-Instruct/prompt.txt"
  fn_completions: "huggingface_local_completions"
  completions_kwargs:
    model_name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
    max_new_tokens: 4096
    use_cache: True
    do_sample: False
    model_kwargs:
      attn_implementation: "flash_attention_2"
      torch_dtype: bfloat16
  pretty_name: "Llama 3.1 8B Instruct"